{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SEMRush & GSC Script - Top Opportunities</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from api import *\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Input Criteria - Form Inputs On-page </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORM INPUT FIELDS\n",
    "\n",
    "domain_lookup = 'https://www.inseev.com/'\n",
    "\n",
    "# GSC Data Input \n",
    "gsc_property = 'https://www.inseev.com/'\n",
    "startdate=\"2020-12-20\" # Make 30 day max\n",
    "enddate=\"2020-12-30\" # Make 30 day max\n",
    "\n",
    "# SEMRush Data\n",
    "## Brand Lookup (\"brandNgram1|brandNgram2|brandNgram3....\")\n",
    "nonbrand_semrush = \"inseev|insev|insv\"\n",
    "semrush_csv= \"inseev.com-organic.Positions-us-20210122-2021-01-23T21_50_40Z.csv\"\n",
    "nlargest_nbKeywords = 15\n",
    "top_pages_sort = 'Search_Volume_semrush' # Dropdown filter (CRITERIA BELOW)\n",
    "top_queries_sort ='Traffic_semrush' # Dropdown filter (CRITERIA BELOW)\n",
    "\n",
    "\n",
    "###### FORM FILL FIELDS / INSTRUCTION #######\n",
    "\n",
    "# GSC Data Input \n",
    "## gsc_property - Input Type: Text Box (Frontend Header: 'GSC Property')\n",
    "## startdate - Input Type: Date Selector (Frontend Header: 'Start Date') - MAX 30 DAY RANGE\n",
    "## enddate - Input Type: Date Selector (Frontend Header: 'End Date') - MAX 30 DAY RANGE\n",
    "\n",
    "# SEMRush Data\n",
    "## nonbrand_semrush - Input Type: Text Box (Frontend Header: 'Brand Exclusions'); Subtext showing \"e.g., brandNgram1|brandNgram2|brandNgram3....\"\n",
    "## semrush_csv - Input Type: CSV Input (Frontend Header: 'CSV Import')\n",
    "## nlargest_nbKeywords - Input Type: Integer (1 to 15)  (Frontend Header: 'Number of Returned Keywords')\n",
    "## top_pages_sort - Input Type: Dropdown Menu (Frontend Header: 'Select Sort by (Top Pages)')\n",
    "\n",
    "### Option #1: 'Search_Volume_semrush' (Frontend Text: \"Total Search Volume (Top 20 KWs)\")\n",
    "### Option #2: 'Keyword_semrush' (Frontend Text: \"Total Keywords (Top 20 KWs)\")\n",
    "\n",
    "## top_queries_sort - Input Type: Dropdown Menu (Frontend Header: 'Select Sort by (Top Keywords)')\n",
    "### Option #1: 'Search_Volume_semrush' (Frontend Text: \"Search Volume\")\n",
    "### Option #2: 'Traffic_semrush' (Frontend Text: \"Estimated Traffic\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PART 1: Get + Clean GSC Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "domain_name = domain_lookup.split(\"www.\")[-1].split(\"//\")[-1].split(\".\")[0]\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Options: 'date,' 'device,' 'page,' , 'query' and \"country\"\n",
    "dimensions=['page','query','device','date']\n",
    "\n",
    "gsc_df = gscservice.get_site_data(\n",
    "    gsc_property,\n",
    "    startdate=startdate,\n",
    "    enddate=enddate,\n",
    "    dimensions=dimensions,\n",
    "     output_fn=\"{}_{}_{}_by_{}.csv\".format(domain_name, startdate.replace(\"-\",\"\"), enddate.replace(\"-\",\"\"), '_'.join(dimensions))\n",
    ")\n",
    "\n",
    "\n",
    "# Filter to only non-brand\n",
    "kw_filter = ~gsc_df[\"query\"].str.contains(\"{}\".format(nonbrand_semrush), case = False, regex=True)\n",
    "gsc_df = gsc_df[kw_filter]\n",
    "\n",
    "\n",
    "# Insert domain & datasetID\n",
    "gsc_df.insert(loc = 2, column = \"domain\", value = domain_lookup)\n",
    "datasetID = \"{}_{}_{}_by_{}\".format(domain_name, startdate.replace(\"-\",\"\"), enddate.replace(\"-\",\"\"), '_'.join(dimensions))\n",
    "gsc_df.insert(loc = 0, column = \"gsc_datasetID\", value = datasetID)\n",
    "\n",
    "gsc_df.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "select_cols = [\"gsc_datasetID\",\"domain\", \"page\", \"query\", \"clicks\", \"impressions\",\"ctr\",\"position\"]\n",
    "gsc_df = gsc_df[select_cols]\n",
    "grouped_gsc = gsc_df.groupby([\"gsc_datasetID\",\"domain\", \"page\",\"query\"])\n",
    "\n",
    "gsc_all_data = gsc_df.groupby([\"gsc_datasetID\",\"domain\",\"page\",\"query\"])\n",
    "gsc_all_data = gsc_all_data.agg({\"clicks\": \"sum\",\n",
    "           \"impressions\": \"sum\",\n",
    "           \"ctr\" : \"mean\",\n",
    "           \"position\":[\"size\",\"max\",\"min\", \"mean\"]})\n",
    "\n",
    "gsc_all_data = gsc_all_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 2: Get + Clean SEMRush Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV + update column names to not contain spaces\n",
    "\n",
    "semrush_df = pandas.read_csv(\"{}\".format(semrush_csv))\n",
    "semrush_df.columns = [column_name.replace(\" \",\"_\") for column_name in semrush_df.columns]\n",
    "\n",
    "# Filter to only non-brand queries\n",
    "filter_kw_type = ~semrush_df[\"Keyword\"].str.contains(\"{}\".format(nonbrand_semrush), case = False, regex=True)\n",
    "semrush_df = semrush_df[filter_kw_type]\n",
    "semrush_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_range(position):\n",
    "    if position < 11:\n",
    "        return \"1 to 10\"\n",
    "    elif position >= 11 and position <= 20:\n",
    "        return \"11 to 20\"\n",
    "    elif position >= 21 and position <= 30:\n",
    "        return \"11 to 20\"\n",
    "    else:\n",
    "        return \"31+\"\n",
    "    \n",
    "def top20(position):\n",
    "    if position < 21:\n",
    "        return \"TRUE\"\n",
    "    else:\n",
    "        return \"FALSE\"\n",
    "    \n",
    "def traffic_exists(traffic):\n",
    "    if traffic > 0:\n",
    "        return \"TRUE\"\n",
    "    else:\n",
    "        return \"FALSE\"\n",
    "    \n",
    "semrush_df[\"Traffic_Cost\"] = semrush_df[\"Traffic_Cost\"].fillna(0).astype(\"int\")\n",
    "\n",
    "\n",
    "select_cols = [\"Keyword\", \"Position\", \"Search_Volume\", \"CPC\", \"URL\", \"Traffic\", \"Traffic_Cost\", \"Timestamp\", \"SERP_Features_by_Keyword\"]\n",
    "semrush_df = semrush_df[select_cols]\n",
    "    \n",
    "semrush_df.insert(loc = 2, column = \"Position_Range\", value = semrush_df[\"Position\"].apply(position_range))\n",
    "semrush_df.insert(loc = 3, column = \"Top20\", value = semrush_df[\"Position\"].apply(top20))\n",
    "semrush_df.insert(loc = 6, column = \"Domain\", value = domain_lookup)\n",
    "semrush_df.insert(loc = 9, column = \"Traffic_Exists\", value = semrush_df[\"Traffic\"].apply(traffic_exists))\n",
    "semrush_df.insert(loc = 9, column = \"Traffic_Rank\", value = semrush_df[\"Traffic\"].rank(ascending = False).astype(int))\n",
    "\n",
    "semrush_df.sort_values(\"Traffic\", ascending = False, inplace = True)\n",
    "semrush_df.columns = [str(col) + '_semrush' for col in semrush_df.columns]\n",
    "semrush_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 3: Scrape Top Pages & Merge Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### [BELOW AGGREGATES PAGES FOR SCRAPER]\n",
    "# Select only areas where \"Top20_semrush\" == True \n",
    "top20filter = semrush_df[\"Top20_semrush\"].str.contains(\"TRUE\", case = False, regex=True)\n",
    "top20queries = semrush_df[top20filter]\n",
    "top20queries = top20queries.sort_values(by = \"Traffic_semrush\", ascending=False)\n",
    "domainFilter = top20queries[\"Domain_semrush\"].str.contains(\"{}\".format(domain_lookup), case = False, regex=True)\n",
    "cleanDomain_top20Queries_df = top20queries[domainFilter]\n",
    "\n",
    "# groupby #1 - page-level\n",
    "semrush_url_group = cleanDomain_top20Queries_df.groupby([\"Domain_semrush\",\"URL_semrush\"])\n",
    "semrush_url_group = semrush_url_group.agg({\"Traffic_semrush\": \"sum\",\n",
    "           \"Position_semrush\":\"mean\", \n",
    "            \"Search_Volume_semrush\": \"sum\",\n",
    "            \"Keyword_semrush\":\"count\"})\n",
    "\n",
    "# reset index and groupby URL_semrush in order to setup for \"for loop\"\n",
    "semrush_url_group = semrush_url_group.reset_index() \n",
    "select_cols = [\"Domain_semrush\",\"URL_semrush\", \"Traffic_semrush\", \"Position_semrush\", \"Search_Volume_semrush\", \"Keyword_semrush\"]\n",
    "semrush_df_columns = semrush_url_group[select_cols]\n",
    "semrush_df_columns  = pandas.DataFrame(columns = semrush_df_columns.columns)\n",
    "\n",
    "# groupby #2 - \"Domain_semrush\" - only 1 item so we'll get top pages w/ nlargest\n",
    "\n",
    "semrush_url_group = semrush_url_group.groupby(\"Domain_semrush\")\n",
    "\n",
    "for URL_semrush, data in semrush_url_group:\n",
    "    highest_keywords_in_group = data.nlargest(25,\"{}\".format(top_pages_sort))\n",
    "    semrush_df_columns = semrush_df_columns.append(highest_keywords_in_group)\n",
    "    \n",
    "top_page_kpis = semrush_df_columns\n",
    "    \n",
    "### [BELOW IS THE SCRAPER]\n",
    "# Dictionaries updated w/ looped data\n",
    "titleTag= {}\n",
    "metaDescription = {}\n",
    "h1Tag = {}\n",
    "\n",
    "semrush_df_columns = (semrush_df_columns[\"URL_semrush\"]).unique()\n",
    "\n",
    "def GET_UA():\n",
    "    uastrings = [\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.72 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10) AppleWebKit/600.1.25 (KHTML, like Gecko) Version/8.0 Safari/600.1.25\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/600.1.17 (KHTML, like Gecko) Version/7.1 Safari/537.85.10\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.104 Safari/537.36\"\\\n",
    "                ]\n",
    " \n",
    "    return random.choice(uastrings)\n",
    "\n",
    "\n",
    "for url in semrush_df_columns:\n",
    "    USER_AGENT = GET_UA()\n",
    "    headers = {'user-agent': USER_AGENT}\n",
    "    resp= requests.get(url, headers=headers)\n",
    "\n",
    "    #Parse the HTML with Beautiful soup\n",
    "    if resp.status_code == 200:\n",
    "        bs = BeautifulSoup(resp.content, \"html.parser\")\n",
    "        \n",
    "    \n",
    "    #to get the title tags\n",
    "    title= bs.find('title')\n",
    "    titleTag.update([(url,title)])\n",
    "    \n",
    "    #to get the h1 tags\n",
    "#     h1 = bs.body.find('h1')\n",
    "#     h1Tag.update([(url,h1)])\n",
    "\n",
    "\n",
    "    #this is to get the meta descriptions\n",
    "    for meta in bs.find_all('meta'):\n",
    "        if meta.get('name')== 'description':\n",
    "            metaDescription.update([(meta.get('content'), url)])\n",
    "\n",
    "# Can use any of the Dictionaries stated at the start of the function\n",
    "\n",
    "titleTag_df = pandas.DataFrame(list(titleTag.items()), columns=[\"Page_Scrape\",\"Title_Scrape\"])\n",
    "# h1Tag_df = pandas.DataFrame(list(h1Tag.items()), columns=[\"Page_Scrape\",\"H1Tag_Scrape\"])\n",
    "# seo_data_scrape_topPages = titleTag_df.merge(h1Tag_df, how=\"inner\", left_on= [\"Page_Scrape\"], right_on=[\"Page_Scrape\"])\n",
    "topPages_Scrape_merge = titleTag_df.merge(top_page_kpis, how=\"inner\", left_on= [\"Page_Scrape\"], right_on=[\"URL_semrush\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform initial groupby to get KPIs we want at the page-level\n",
    "top20queries_2 = semrush_df[top20filter]\n",
    "semrush_topQuery_df = top20queries_2.groupby([\"Domain_semrush\",\"URL_semrush\",\"Keyword_semrush\"])\n",
    "semrush_topQuery_df = semrush_topQuery_df.agg({\"Traffic_semrush\": \"sum\",\n",
    "           \"Position_semrush\":\"mean\", \n",
    "            \"Search_Volume_semrush\": \"sum\"})\n",
    "\n",
    "# reset index and groupby URL_semrush in order to setup for \"for loop\"\n",
    "semrush_topQuery_df = semrush_topQuery_df.reset_index() \n",
    "\n",
    "select_cols_pt2 = [\"Domain_semrush\",\"URL_semrush\", \"Keyword_semrush\", \"Traffic_semrush\", \"Position_semrush\", \"Search_Volume_semrush\"]\n",
    "semrush_df_columns_pt2 = semrush_topQuery_df[select_cols]\n",
    "semrush_df_columns_pt2  = pandas.DataFrame(columns = semrush_df_columns_pt2.columns)\n",
    "\n",
    "# For loop to get top XX queries\n",
    "semrush_topQuery_df = semrush_topQuery_df.groupby(\"URL_semrush\")\n",
    "semrush_topQuery_df\n",
    "\n",
    "for URL_semrush, data in semrush_topQuery_df:\n",
    "    highest_keywords_in_group = data.nlargest(int(\"{}\".format(nlargest_nbKeywords)),\"{}\".format(top_queries_sort))\n",
    "    semrush_df_columns_pt2 = semrush_df_columns_pt2.append(highest_keywords_in_group)\n",
    "    \n",
    "merge_top20 = semrush_df_columns_pt2.merge(topPages_Scrape_merge, how=\"left\", left_on= [\"URL_semrush\", \"Domain_semrush\"], right_on=[\"URL_semrush\", \"Domain_semrush\"])\n",
    "merge_top20_gsc = merge_top20.merge(gsc_all_data, how=\"left\",  left_on= [\"URL_semrush\", \"Keyword_semrush_x\"], right_on=[('page',''), ('query','')])\n",
    "\n",
    "merge_top20_gsc = merge_top20_gsc.rename(mapper={\"Keyword_semrush_y\":\"#_keywords_top20\",\n",
    "                                        'Traffic_semrush_y':'est_traffic_top20',\n",
    "                                         \"Search_Volume_semrush_y\": \"total_volume_top20\",\n",
    "                                         \"Traffic_semrush_x\":\"total_keywords_top20\", \n",
    "                                         \"Keyword_semrush_x\":\"top_keywords\", \n",
    "                                         \"query\": \"matching_gsc_query\",\n",
    "                                         \"Search_Volume_semrush_x\":\"top_keyword_volume\", \n",
    "                                         \"Position_semrush_x\":\"top_keyword_position\", \n",
    "                                         \"Traffic_semrush_x\":\"top_keyword_traffic\",\n",
    "                                        (\"clicks\",\"sum\"):\"clicks_gsc\",\n",
    "                                        (\"impressions\",\"sum\"):\"impressions_gsc\",\n",
    "#                                         \"H1Tag_Scrape\": \"H1_tag\",\n",
    "                                        \"Title_Scrape\": \"Title_tag\",\n",
    "                                         \"URL_semrush\": \"URL_semrush\"}, axis=\"columns\")\n",
    "\n",
    "\n",
    "select_cols_final = [\"URL_semrush\",\"Title_tag\", \"#_keywords_top20\", \"est_traffic_top20\", \"total_volume_top20\", \"top_keywords\",\"top_keyword_volume\",\"top_keyword_position\", \"top_keyword_traffic\",\"clicks_gsc\",\"impressions_gsc\"]\n",
    "merge_top20_gsc = merge_top20_gsc[select_cols_final]\n",
    "naFilter = merge_top20_gsc[\"#_keywords_top20\"].notna()\n",
    "merge_top20_final = merge_top20_gsc[naFilter]\n",
    "\n",
    "merge_top20_final.to_csv(\"semrush-opportunity-analysis_{}-{}.csv\".format(domain_name,date),  index=True)\n",
    "merge_top20_final.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
